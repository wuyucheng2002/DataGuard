{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self) -> None:\n",
    "        # 读取数据\n",
    "        self.train_dataset = self.get_data('./Adult/adult.data', isTest=False)\n",
    "        self.test_dataset = self.get_data('./Adult/adult.test', isTest=True)\n",
    "        # 数据处理\n",
    "        self.train_dataset, self.test_dataset = self.data_process(self.train_dataset, self.test_dataset)\n",
    "        # 获取数据基本信息\n",
    "        self.num_of_train = self.train_dataset.shape[0]  # 训练集大小\n",
    "        self.num_of_test = self.test_dataset.shape[0]  # 测试集大小\n",
    "        self.num_of_features = self.train_dataset[:, :-1].shape[1]  # 特征个数\n",
    "        self.num_of_label = 2  # 标签个数\n",
    "\n",
    "        self.train_features = self.train_dataset[:, :-1]  # 训练集X\n",
    "        self.train_label = self.train_dataset[:, -1]  # 训练集y\n",
    "        self.test_features = self.test_dataset[:, :-1]  # 测试集X\n",
    "        self.test_label = self.test_dataset[:, -1]  # 测试集y\n",
    "\n",
    "    @staticmethod\n",
    "    def get_data(filepath, isTest=False):\n",
    "        \"\"\"\n",
    "        读取数据\n",
    "        :param filepath: adult.data/adult.test文件的存放位置\n",
    "        :param isTest: 读取的数据是否是测试集\n",
    "        :return: 去除空值后的数据，以dataframe形式返回\n",
    "        \"\"\"\n",
    "        line_list = []\n",
    "        with open(filepath) as lines:\n",
    "            if isTest:\n",
    "                next(lines)\n",
    "            for line in lines:\n",
    "                l = line.split(',')\n",
    "                if '?' in l:\n",
    "                    print('yes')\n",
    "                line_list.append(l)\n",
    "\n",
    "        data = pd.DataFrame(line_list,\n",
    "                            columns=['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                                     'marital-status', 'occupation', 'relationship',\n",
    "                                     'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                                     'native-country', 'label'])\n",
    "\n",
    "        # 丢弃最后一行空行\n",
    "        data = data.iloc[:-1, :]\n",
    "\n",
    "        for col in ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']:\n",
    "            data[col] = data[col].astype(int)\n",
    "\n",
    "        for col in ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'native-country',\n",
    "                    'sex', 'label']:\n",
    "            data[col] = data[col].astype(str)\n",
    "            data[col] = data[col].apply(lambda x: x.strip(' '))\n",
    "            data[col] = data[col].apply(lambda x: None if x == '?' else x)\n",
    "\n",
    "        data['label'] = data['label'].apply(lambda l: l.strip())\n",
    "\n",
    "        data.dropna(axis='index', how='any', inplace=True)\n",
    "\n",
    "        data['sex'] = data['sex'].apply(lambda x: 0 if x == 'Male' else 1)\n",
    "\n",
    "        data['label'] = data['label'].apply(lambda x: 0 if x.strip('.') == '<=50K' else 1)\n",
    "\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def data_process(train_dataset, test_dataset):\n",
    "        \"\"\"\n",
    "        数据预处理：\n",
    "        1. 对于类别型属性转化为one-hot编码\n",
    "        2. 对于数值型属性进行Min-Max归一化\n",
    "        :param train_dataset: 读取的训练数据，dataframe\n",
    "        :param test_dataset: 读取的测试数据，dataframe\n",
    "        :return: (train_dataset, test_dataset), 都是array\n",
    "        \"\"\"\n",
    "        X_train_raw = train_dataset.drop(columns=['sex'])\n",
    "        y_train = np.array(train_dataset['sex'])\n",
    "\n",
    "        X_test_raw = test_dataset.drop(columns=['sex'])\n",
    "        y_test = np.array(test_dataset['sex'])\n",
    "\n",
    "        num_col = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'label']\n",
    "        cat_col = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'native-country']\n",
    "\n",
    "        full_pipeline = ColumnTransformer([\n",
    "            (\"num\", MinMaxScaler(), num_col),\n",
    "            (\"cat\", OneHotEncoder(), cat_col)])\n",
    "\n",
    "        X_train = full_pipeline.fit_transform(X_train_raw).toarray()\n",
    "        X_test = full_pipeline.transform(X_test_raw).toarray()\n",
    "\n",
    "        train_dataset = np.concatenate([X_train, y_train.reshape((y_train.shape[0], -1))], axis=1)\n",
    "        test_dataset = np.concatenate([X_test, y_test.reshape((y_test.shape[0], -1))], axis=1)\n",
    "\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def load_array(data_arrays, batch_size, is_train=True):\n",
    "        \"\"\"\n",
    "        以batch加载数据\n",
    "        :param data_arrays: (X_array, y_array)\n",
    "        :param batch_size: batch的大小\n",
    "        :param is_train: 传入的数据是否是训练集，如果是则会随机打乱顺序\n",
    "        :return: 数据迭代器，每次返回一个batch的数据\n",
    "        \"\"\"\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(data_arrays)\n",
    "        if is_train:\n",
    "            dataset = dataset.shuffle(buffer_size=len(data_arrays), seed=42)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "\n",
    "        return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "data = Data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.30136986, 0.04333771, 0.8       , ..., 1.        , 0.        ,\n        0.        ],\n       [0.45205479, 0.04727738, 0.8       , ..., 1.        , 0.        ,\n        0.        ],\n       [0.28767123, 0.1372439 , 0.53333333, ..., 1.        , 0.        ,\n        0.        ],\n       ...,\n       [0.56164384, 0.09391367, 0.53333333, ..., 1.        , 0.        ,\n        0.        ],\n       [0.06849315, 0.1276201 , 0.53333333, ..., 1.        , 0.        ,\n        0.        ],\n       [0.47945205, 0.18638336, 0.53333333, ..., 1.        , 0.        ,\n        0.        ]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "log = LogisticRegression(max_iter=1000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.84352727, 0.85479861, 0.85361406, 0.84797745, 0.84996684])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(log, data.train_features, data.train_label, cv=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_iter = data.load_array((data.train_features, data.train_label))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
